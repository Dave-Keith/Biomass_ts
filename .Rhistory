i=9
subset(db,Stock.ID==unique(db$Stock.ID)[i])
#############  End Section 1 Data Processing#############  End Section 1 Data Processing#############  End Section 1 Data Processing
#############  Section 2 Data Exploration#############  Section 2 Data Exploration#############  Section 2 Data Exploration
#############  Section 2 Data Exploration#############  Section 2 Data Exploration#############  Section 2 Data Exploration
#############  Section 2 Data Exploration#############  Section 2 Data Exploration#############  Section 2 Data Exploration
### OK, now we have the data, time to start walking through the models properly
### First lets take a look at our data....
# Let's look and see what we have over time
# Well even in 1946 we have 3 populations which is nice, by 1950 we have 5, 1955 there are 10 and at the
# peak we have 1000, drops back to 10 by 2010 but hopefully we can update that!!  We have 100 in the late 90's and  over
# 20 stocks from 1961 onwards, hit 50 in 1976 and are at 80 in 1982
aggregate(total_stan~Year,db,FUN=length)
range(aggregate(total_stan~Stock.ID,db,FUN=length)$V1) # Everything has at least 10 years
# On average the time series are 33 years long, nice!
median(aggregate(total_stan~Stock.ID,db,FUN=length)$V1)
# How does this break down by other covariates?  ICES and NOAA dominate the analysis, maybe 10% of data are other locations
aggregate(total_stan~Management,db,FUN=length)
# First we need to set up the plotting area, I hate lattice so I'm doing this my way...
# Set the number of rows
nr <- ceiling(sqrt(length(unique(db$Stock.ID))))
# Set the number of columns, the funky little command is used to add one to the nc if nr is a perfect square
# As we are printing nchains + 1
ifelse(sqrt(length(unique(db$Stock.ID))) %% 1==0,  nc <- ceiling(sqrt(length(unique(db$Stock.ID))))+1,
nc <- ceiling(sqrt(length(unique(db$Stock.ID)))))
windows(15,15)
ly <- layout(matrix(c(1:(nr*nc)), nr, nc, byrow = T))
layout.show(ly)
par(mar=c(0,0,2,0))
for(i in 1:length(unique(db$Stock.ID)))
{
with(subset(db,Stock.ID==unique(db$Stock.ID)[i]),plot(old_stan~Year,pch=16,cex=0.01,xaxt="n",yaxt="n",bty="U"))
title(unique(db$Stock.ID)[i],cex.main=0.7)
} # end for(i in 1:length(unique(mw$year)))
windows(15,15)
ly <- layout(matrix(c(1:(nr*nc)), nr, nc, byrow = T))
layout.show(ly)
par(mar=c(0,0,2,0))
for(i in 1:length(unique(db$Stock.ID)))
{
with(subset(db,Stock.ID==unique(db$Stock.ID)[i]),plot(old_stan~Year,pch=16,cex=0.01,xaxt="n",yaxt="n",bty="U"))
title(unique(db$Stock.ID)[i],cex.main=0.7)
} # end for(i in 1:length(unique(mw$year)))
windows(15,15)
ly <- layout(matrix(c(1:(nr*nc)), nr, nc, byrow = T))
layout.show(ly)
par(mar=c(0,0,2,0))
for(i in 1:length(unique(db$Stock.ID)))
{
with(subset(db,Stock.ID==unique(db$Stock.ID)[i]),plot(young_stan~Year,pch=16,cex=0.01,xaxt="n",yaxt="n",bty="U"))
title(unique(db$Stock.ID)[i],cex.main=0.7)
} # end for(i in 1:length(unique(mw$year)))
windows(15,15)
ly <- layout(matrix(c(1:(nr*nc)), nr, nc, byrow = T))
layout.show(ly)
par(mar=c(0,0,2,0))
for(i in 1:length(unique(db$Stock.ID)))
{
with(subset(db,Stock.ID==unique(db$Stock.ID)[i]),plot(total_stan~Year,pch=16,cex=0.01,xaxt="n",yaxt="n",bty="U"))
title(unique(db$Stock.ID)[i],cex.main=0.7)
} # end for(i in 1:length(unique(mw$year)))
unique.stocks
subset(db,Stock.ID=="SARDPVIIIc-IXa")
rm(list=ls(all=T))
library(matlab)
library(lme4)
library(arm)
library(gamm4)
#setwd("d:/Dropbox/My_Papers/Biomass_and_age/")
setwd("d:/Github/Current_papers/Biomass_ts")
ASD_MGMT<-read.csv("ASD_MGMT.csv", header=T,stringsAsFactors = F)
# Currently the mid-point of most time series is 1989...
mean.year <- round(mean(ASD_MGMT$Year))
ASD_MGMT$Year_cen <- ASD_MGMT$Year-mean.year
geo.mean <- function(x,n) prod(x)^(1/n)
unique.stocks <- as.character(unique(ASD_MGMT$Stock.ID))
num.stocks <- length(unique.stocks)
# What are we going to pick as our variable to look at?
# Options are any of the age specific variables... "SSB","BM","Num","Catch","FM",
var <- "BM"
db <- NULL
ages <- NULL
age.quan <- NULL
young.ages <- NULL
old.ages <- NULL
i=18
# so we want to run a loop to grab the biomass estiamtes for each stock
for(i in 1:num.stocks)
{
# Several of these stocks have a male and female entry, so we'll exclude the males
# Get the stock information....
name <- unique.stocks[i]
if(is.element(name,c("ALPLAICBSAIm","ARFLOUNDBSAIm","GHALBSAIm","NRSOLEEBSAIm","YSOLEBSAIm"))==F)
{
# Grab the names of the stock descriptors to keep and then subset the data by stock and to pull the appropriate
# variable defined by var above.
dat.names <- c("Stock.ID","Management","Area","Order","Family","Genus","Species","LME","Year","Year_cen")
dat <- subset(ASD_MGMT, Stock.ID == name ,select = c(dat.names,names(ASD_MGMT[,grep(var,names(ASD_MGMT))])))
# Determine which (if any) columns and rows have data
cols <- which(colSums(dat[,grep(var,names(dat))],na.rm=T) > 0)
rows <- which(rowSums(subset(dat,select = -c(which(names(dat) %in% dat.names))),na.rm=T) == 0)
# Remove any columns with no data
if(length(cols) > 0)
{
db[[name]] <- dat[,c(1:length(dat.names),cols + length(dat.names))]
} # end if(length(cols) > 0)
# Remove any years with no data
if(length(rows) > 0)
{
db[[name]] <- db[[name]][-rows,]
} # end if(length(rows) > 0)
# If we have data...
if(is.null(db[[name]]) == F)
{
# OK, this is a bizarro way to get the ages but it does the trick! Following line grabs the variable names...
ages[[name]]  <- as.numeric(substr(names(db[[name]][(grep("[[:digit:]]",
names(db[[name]])))]),start=(nchar(var)+2),stop=(nchar(var)+3)))
var.names <- names(db[[name]][(grep("[[:digit:]]",names(db[[name]])))])
# Now we break the ages into old and young quantiles, this splits the data into the oldest 25% and youngest 25% of ages
# Note that we don't think of + groups and that we round so that often it's not 25% (e.g. sometimes 20%, others may be 30%)
age.quan[[name]] <- quantile(ages[[name]])
#First the young
young.ages[[name]] <- round(age.quan[[name]][1]):round(age.quan[[name]][2])
var.names.young <- var.names[1:length(young.ages[[name]])]
# Now for the old
old.ages[[name]] <- round(age.quan[[name]][4]):round(age.quan[[name]][5])
var.names.old <- var.names[(length(ages[[name]]) - length(old.ages[[name]] ) +1) : length(ages[[name]])]
# A few differnt ways to define our response variable, stan might be the most statisically
# pleasing one, I think ratio is the easiest transformation to wrap my head around and to
# use when comparing models but statistical properties are wonderful
# The offset might work nicely in terms of the model too and avoid transformation concerns...
db[[name]]$total <- rowSums(subset(db[[name]],select = -c(which(names(db[[name]]) %in% dat.names))),na.rm=T)
# Replace 0's with half minimum non-zero value in time series just so log works
if(any(db[[name]]$total == 0))db[[name]]$total[db[[name]]$total == 0] <- 0.5*min(db[[name]]$total[db[[name]]$total > 0])
db[[name]]$total_ratio   <- db[[name]]$total/max(db[[name]]$total,na.rm=T)
db[[name]]$total_stan   <- scale(log(db[[name]]$total))
db[[name]]$total_offset   <- max(db[[name]]$total,na.rm=T)
db[[name]]$old   <- rowSums(subset(db[[name]],select = c(which(names(db[[name]]) %in% var.names.old))),na.rm=T)
# Replace 0's with half minimum value in time series just so log works
if(any(db[[name]]$old == 0))db[[name]]$old[db[[name]]$old == 0] <- 0.5*min(db[[name]]$old[db[[name]]$old > 0])
db[[name]]$old_ratio   <- db[[name]]$old/max(db[[name]]$old,na.rm=T)
db[[name]]$old_stan   <- scale(log(db[[name]]$old))
db[[name]]$old_offset   <- max(db[[name]]$old,na.rm=T)
db[[name]]$young <- rowSums(subset(db[[name]],select = c(which(names(db[[name]]) %in% var.names.young))),na.rm=T)
# Replace 0's with half minimum value in time series just so log works
if(any(db[[name]]$young == 0))db[[name]]$young[db[[name]]$young == 0] <- 0.5*min(db[[name]]$young[db[[name]]$young > 0])
db[[name]]$young_ratio   <- db[[name]]$young/max(db[[name]]$young,na.rm=T)
db[[name]]$young_offset   <- max(db[[name]]$young,na.rm=T)
db[[name]]$young_stan   <- scale(log(db[[name]]$young))
# Now we can remove the individual age data as that's not especially necessary to keep
db[[name]] <- subset(db[[name]],select = -c(which(names(db[[name]]) %in% var.names)))
} # end if(length(cols) > 0 && length(rows) > 0)
} # end if(is.element(name,c("ALPLAICBSAIm","ARFLOUNDBSAIm","GHALBSAIm","NRSOLEEBSAIm","YSOLEBSAIm"))==F)
} # end for(i in 1:num.stocks)
# Make sure the columns all the same length
range(lapply(db,ncol))
db <- do.call("rbind",db)
dim(db)
i=9
subset(db,Stock.ID==unique(db$Stock.ID)[i])
#############  End Section 1 Data Processing#############  End Section 1 Data Processing#############  End Section 1 Data Processing
#############  Section 2 Data Exploration#############  Section 2 Data Exploration#############  Section 2 Data Exploration
#############  Section 2 Data Exploration#############  Section 2 Data Exploration#############  Section 2 Data Exploration
#############  Section 2 Data Exploration#############  Section 2 Data Exploration#############  Section 2 Data Exploration
### OK, now we have the data, time to start walking through the models properly
### First lets take a look at our data....
# Let's look and see what we have over time
# Well even in 1946 we have 3 populations which is nice, by 1950 we have 5, 1955 there are 10 and at the
# peak we have 1000, drops back to 10 by 2010 but hopefully we can update that!!  We have 100 in the late 90's and  over
# 20 stocks from 1961 onwards, hit 50 in 1976 and are at 80 in 1982
aggregate(total_stan~Year,db,FUN=length)
range(aggregate(total_stan~Stock.ID,db,FUN=length)$V1) # Everything has at least 10 years
# On average the time series are 33 years long, nice!
median(aggregate(total_stan~Stock.ID,db,FUN=length)$V1)
# How does this break down by other covariates?  ICES and NOAA dominate the analysis, maybe 10% of data are other locations
aggregate(total_stan~Management,db,FUN=length)
# First we need to set up the plotting area, I hate lattice so I'm doing this my way...
# Set the number of rows
nr <- ceiling(sqrt(length(unique(db$Stock.ID))))
# Set the number of columns, the funky little command is used to add one to the nc if nr is a perfect square
# As we are printing nchains + 1
ifelse(sqrt(length(unique(db$Stock.ID))) %% 1==0,  nc <- ceiling(sqrt(length(unique(db$Stock.ID))))+1,
nc <- ceiling(sqrt(length(unique(db$Stock.ID)))))
windows(15,15)
ly <- layout(matrix(c(1:(nr*nc)), nr, nc, byrow = T))
layout.show(ly)
par(mar=c(0,0,2,0))
for(i in 1:length(unique(db$Stock.ID)))
{
with(subset(db,Stock.ID==unique(db$Stock.ID)[i]),plot(old_stan~Year,pch=16,cex=0.01,xaxt="n",yaxt="n",bty="U"))
title(unique(db$Stock.ID)[i],cex.main=0.7)
} # end for(i in 1:length(unique(mw$year)))
# Now look at the young folks...
windows(15,15)
ly <- layout(matrix(c(1:(nr*nc)), nr, nc, byrow = T))
layout.show(ly)
par(mar=c(0,0,2,0))
for(i in 1:length(unique(db$Stock.ID)))
{
with(subset(db,Stock.ID==unique(db$Stock.ID)[i]),plot(young_stan~Year,pch=16,cex=0.01,xaxt="n",yaxt="n",bty="U"))
title(unique(db$Stock.ID)[i],cex.main=0.7)
} # end for(i in 1:length(unique(mw$year)))
# Now look at the total
windows(15,15)
ly <- layout(matrix(c(1:(nr*nc)), nr, nc, byrow = T))
layout.show(ly)
par(mar=c(0,0,2,0))
for(i in 1:length(unique(db$Stock.ID)))
{
with(subset(db,Stock.ID==unique(db$Stock.ID)[i]),plot(total_stan~Year,pch=16,cex=0.01,xaxt="n",yaxt="n",bty="U"))
title(unique(db$Stock.ID)[i],cex.main=0.7)
} # end for(i in 1:length(unique(mw
direct = "d:/r/"
yr = as.numeric(format(Sys.time(), "%Y")) -1
source(paste(direct,"DIYBiplot.R",sep=""))
source(paste(direct,"HighstatLibV9.R",sep=""))
names(db)
Vars <- c("Year_cen","total","total_ratio","total_stan","total_offset""old"          "old_ratio"
"old_stan"     "old_offset"   "young"        "young_ratio"  "young_offset" "young_stan"  )
Vars <- c("Year_cen","total","total_ratio","total_stan","total_offset","old"  ,        "old_ratio"
"old_stan"  ,   "old_offset"  , "young"     ,   "young_ratio" , "young_offset", "young_stan"  )
Vars <- c("Year_cen","total","total_ratio","total_stan","total_offset","old"  ,        "old_ratio"   ,
"old_stan"  ,   "old_offset"  , "young"     ,   "young_ratio" , "young_offset", "young_stan"  )
Mydotplot(mw[,Vars])
Mydotplot(mw[,Vars])
library(lattice)
Mydotplot(mw[,Vars])
Mydotplot(db[,Vars])
windows(11,8.5)
Vars <- c("Year_cen","total","total_ratio","total_stan","total_offset","old"  ,        "old_ratio"   ,
"old_stan"  ,   "old_offset"  , "young"     ,   "young_ratio" , "young_offset", "young_stan"  )
pairs(db[,Vars],lower.panel=panel.cor)
aggregate(young.stan~year,db,FUN=mean) # How does the mean change each year
aggregate(young_stan~year,db,FUN=mean) # How does the mean change each year
aggregate(young_stan~Year,db,FUN=mean) # How does the mean change each year
plot(aggregate(young_stan~Year,db,FUN=mean),main="Meat Weight mean") # Here again it's after 1996 that biggest jump happens.\
aggregate(young_stan~Year,db,FUN=mean) # How does the mean change each year
plot(aggregate(old_stan~Year,db,FUN=mean),main="Meat Weight mean") # Can see a pretty steady decline in this!!
plot(aggregate(total_stan~Year,db,FUN=mean),main="Meat Weight mean") # Can see a pretty steady decline in this!!
plot(aggregate(young_ratio~Year,db,FUN=mean),main="Meat Weight mean") # Can see a pretty steady decline in this!!
plot(aggregate(old_ratio~Year,db,FUN=mean),main="Old Ratio mean") # See that rebound in 2000, curious
plot(aggregate(total_ratio~Year,db,FUN=mean),main="Total Ratio mean") # more cyclic then the others, again some 2000 rebound evidence.
plot(aggregate(total_ratio~Year,db,FUN=mean),main="Total Ratio mean") # more cyclic then the others, again some 2000 rebound evidence.
plot(aggregate(total_ratio~Year,db,FUN=mean),main="Total Ratio mean") # more cyclic then the others, again some 2000 rebound evidence.
windows(11,8.5)
plot(aggregate(total_ratio~Year,db,FUN=mean),main="Total Ratio mean") # more cyclic then the others, again some 2000 rebound evidence.
plot(aggregate(old_ratio~Year,db,FUN=mean),main="Old Ratio mean") # collapse as we move into the 70's (given new stocks coming
plot(aggregate(young_ratio~Year,db,FUN=mean),main="Young Ratio mean") # Can see a pretty steady decline in this!!
plot(aggregate(old_ratio~Year,db,FUN=mean),main="Old Ratio mean") # collapse as we move into the 70's (given new stocks coming
plot(aggregate(young_ratio~Year,db,FUN=mean),main="Young Ratio mean") # Can see a pretty steady decline in this!!
aggregate(old_ratio~Year,db,FUN=sd) # How does the variance change each year
plot(aggregate(old_ratio~Year,db,FUN=sd),main="Old ratio Variance") # Here it sure looks like 1996 is the issue, but also around 2005
install.packages("D:/R/PED custom packages/SSModeljags_1.0-0.zip", repos = NULL, type = "win.binary")
aggregate(old_ratio~Year,db,FUN=sd) # How does the variance change each year
windows(11,8.5)
plot(aggregate(old_ratio~Year,db,FUN=sd),main="Old ratio Variance") # Can see early in the time series we might have a problem
aggregate(young_ratio~Year,db,FUN=sd) # How does the variance change each year
plot(aggregate(young_ratio~Year,db,FUN=sd),main="Young ratio Variance") # Can see early in the time series we might have a problem
plot(aggregate(total_ratio~Year,db,FUN=sd),main="Total ratio Variance") # For the young the data actually looks solid variance wize.
aggregate(total_ratio~Year,db,FUN=sd) # How does the variance change each year
windows(11,8.5)
par(mfrow=c(3,1))
plot(aggregate(old_ratio~Year,db,FUN=sd),main="Old ratio Variance") # Can see early in the time series we might have a problem
# since the stocks are all starting at maximum in late 1940's, but it evens out very quickly.  There is a steady decline
# which is likely a function of the high ratios disappearing.
plot(aggregate(young_ratio~Year,db,FUN=sd),main="Young ratio Variance") # For the young the data actually looks solid variance wize.
plot(aggregate(total_ratio~Year,db,FUN=sd),main="Total ratio Variance") # For the total see it is low early as well, good by the 60's
aggregate(old_stan~Year,db,FUN=sd) # How does the variance change each year
aggregate(young_stan~Year,db,FUN=sd) # How does the variance change each year
aggregate(total_stan~Year,db,FUN=sd) # How does the variance change each year
windows(11,8.5)
par(mfrow=c(3,1))
plot(aggregate(old_stan~Year,db,FUN=sd),main="Old stan Variance") # Can see early in the time series we might have a problem
# since the stocks are all starting at maximum in late 1940's, but it evens out very quickly.  There is a steady decline
# which is likely a function of the high ratios disappearing.
plot(aggregate(young_stan~Year,db,FUN=sd),main="Young stan Variance") # For the young the data actually looks solid variance wize.
plot(aggregate(total_stan~Year,db,FUN=sd),main="Total stan Variance") # For the tot
aggretate(old_stan~Management,FUN=mean)
aggregate(old_stan~Management,FUN=mean)
aggregate(old_stan~Management,db,FUN=mean)
boxplot(old_stan~Management,db)
windows(11,8.5)
par(mfrow=c(3,1))
boxplot(old_stan~Management,db)
boxplot(young_stan~Management,db)
boxplot(total_stan~Management,db)
windows(11,8.5)
par(mfrow=c(3,1))
boxplot(old_ratio~Management,db)
boxplot(young_ratio~Management,db)
boxplot(total_ratio~Management,db)
aggregate(young_ratio~Management,db,FUN=mean)
aggregate(old_ratio~Management,db,FUN=mean)
aggregate(total_ratio~Management,db,FUN=mean)
unique(db$Species)
unique(db$Order)
unique(db$Family)
unique(db$LME)
xtabs(old_stan~Management)
xtabs(old_stan~Management,db)
xtabs(old_ratio~Management,db)
table(old_ratio~Management,db)
table(old_ratio,Management,db)
table(db)
table(subset(db,select=c("Management","Species"))
)
table(subset(db,select=c("Management","Order"))
)
help(bxp)
boxplot(young_ratio~list(Management,Year))
boxplot(young_ratio~list(Management,Year),db)
boxplot(young_ratio~Year),db)
boxplot(young_ratio~Year,db)
boxplot(young_ratio~interaction(Management,Year),db)
boxplot(young_ratio~interaction(Year,Management),db)
windows(15,8.5)
boxplot(old_ratio~interaction(Year,Management),db)
boxplot(young_ratio~interaction(Year,Management),db)
boxplot(total_ratio~interaction(Year,Management),db)
# Here's the standarized data...
windows(15,8.5)
par(mfrow=c(3,1))
boxplot(old_stan~interaction(Year,Management),db)
boxplot(young_stan~interaction(Year,Management),db)
boxplot(total_stan~interaction(Year,Management),db)
aggregate(old_ratio~Order,db,FUN=mean)
aggregate(young_ratio~Order,db,FUN=mean)
aggregate(total_ratio~Order,db,FUN=mean)
aggregate(old_ratio~Order,db,FUN=mean)
aggregate(young_ratio~Order,db,FUN=mean)
aggregate(total_ratio~Order,db,FUN=mean)
aggregate(old_stan~Order,db,FUN=mean)
aggregate(young_stan~Order,db,FUN=mean)
aggregate(total_stan~Order,db,FUN=mean)
boxplot(old_stan~Order,db,main="old")
windows(11,8.5)
par(mfrow=c(3,1))
boxplot(old_ratio~Order,db,main="old")
boxplot(young_ratio~Order,db,main="young")
boxplot(total_ratio~Order,db,main="total")
aggregate(old_stan~Management,db,FUN=mean)
aggregate(young_stan~Management,db,FUN=mean)
par(mfrow=c(3,1))
boxplot(old_stan~Management,db,main="old")
boxplot(young_stan~Management,db,main="young")
boxplot(total_stan~Management,db,main="total")
aggregate(total_stan~Management,db,FUN=mean)
boxplot(old_stan~interaction(Year,Management),db)
windows(15,8.5)
par(mfrow=c(3,1))
boxplot(old_ratio~interaction(Year,Order),db)
boxplot(young_ratio~interaction(Year,Order),db)
boxplot(total_ratio~interaction(Year,Order),db)
unique(db$Area)
mod.1.old.stan <- lm(old~Year,data=db) # note their used to be a mod.1 when we had outliers in the data, they've been taken care of so mod.1 is gone..
summary(mod.1.old.stan) # shocking to see there is a relationship, and it is strong
mod.1.old.stan <- lm(old_stan~Year,data=db) # note their used to be a mod.1 when we had outliers in the data, they've been taken care of so mod.1 is gone..
# What's it look like
summary(mod.1.old.stan) # shocking to see there is a relationship, and it is strong
windows(11,8.5)
par(mfrow=c(2,2))
plot(mod.2)
windows(11,8.5)
par(mfrow=c(2,2))
plot(mod.1.old.stan)
mod.1.old.rat <- lm(old_ratio~Year,data=db) # note their used to be a mod.1 when we had outliers in the data, they've been taken care of so mod.1 is gone..
summary(mod.1.old.rat)
windows(11,8.5)
windows(11,8.5)
par(mfrow=c(2,2))
plot(mod.1.old.rat)
E1.old.rat <- resid(mod.1.old.rat, type = "pearson")
Dispersion <- sum(E1.old.rat^2) / mod.1.old.rat$df.res
Dispersion
Disp.stan <- sum(E1.old.stan^2) / mod.1.old.stan$df.res
E1.old.rat <- resid(mod.1.old.rat, type = "pearson")
Dispersion <- sum(E1.old.rat^2) / mod.1.old.rat$df.res
Dispersion
E1.old.stan <- resid(mod.1.old.stan, type = "pearson")
Disp.stan <- sum(E1.old.stan^2) / mod.1.old.stan$df.res
Disp.stan
gam.E1.old.rat <- gam(E1.old.rat~te(F1.old.rat))
summary(gam.E1.old.rat) # 10% of deviance explained by this, ugh...
windows(11,8.5)
plot(gam.E1.old.rat) #Clearly underestimating at both low and high shell heights.
E1.old.rat <- resid(mod.1.old.rat, type = "pearson")
E1.old.stan <- resid(mod.1.old.stan, type = "pearson")
gam.E1.old.rat <- gam(E1.old.rat~te(F1.old.rat))
F1.old.stan <- fitted(mod.1.old.stan)
F1.old.rat <- fitted(mod.1.old.rat)
gam.E1.old.rat <- gam(E1.old.rat~te(F1.old.rat))
summary(gam.E1.old.rat) # 10% of deviance explained by this, ugh...
windows(11,8.5)
plot(gam.E1.old.rat) #Clearly underestimating at both low and high shell heights.
gam.E1.old.stan <- gam(E1.old.stan~te(F1.old.stan))
summary(gam.E1.old.stan) # Only 3% of residual variance explained
gam.E1.old.stan <- gam(E1.old.stan~te(F1.old.stan))
summary(gam.E1.old.stan) # Only 2% of residual variance explained, but significant trend..
windows(11,8.5)
plot(gam.E1.old.stan) #Clearly underestimating early and late years...
F1.old.stan
windows(11,8.5)
par(mfrow=c(1,1))
plot(x = F3,
y = E3,
xlab = "Fitted values",
ylab = "Pearson residuals")
abline(h=0,col="blue",lty=2)
windows(11,8.5)
par(mfrow=c(1,1))
plot(x = F1.old.stan,
y = E1.old.stan,
xlab = "Fitted values",
ylab = "Pearson residuals")
abline(h=0,col="blue",lty=2)
# What is the residual trend?
gam.E1.old.stan <- gam(E1.old.stan~te(F1.old.stan))
summary(gam.E1.old.stan) # Only 2% of res
windows(11,8.5)
plot(gam.E1.old.stan) # Clearly a trend in residuals with E b
windows(11,8.5)
plot(E1.old.stan ~db$Year)
abline(h=0,col="blue",lty=2)
gam.E1.old.stan.year <- gam(E1.old.stan~te(db$Year_cen))
center_year <- db$Year_cen
gam.E1.old.stan.year <- gam(E1.old.stan~te(center_year))
summary(gam.E1.old.stan.year) # Only 2% of residual variance explained, but significant trend..
windows(11,8.5)
plot(gam.E1.old.stan.year) # Clearly a trend in residuals with E being too high at both low and high fitted values...
plot(old_stan~Year,data=db)
plot(old_stan~Year,data=db)
windows(11,8.5)
plot(old_stan~Year,data=db)
old_stan
Year
plot(old_ratio~Year,data=db)
plot(old_stan~Year,data=db)
plot(old_ratio~Year,data=db)
windows(11,8.5)
plot(old_ratio~Year,data=db)
summary(mod.1.old.stan)
summary(mod.1.old.rat)
names(db)
mod.1.old.offset <- lm(old~Year, data=db,offset=old_offset)
summary(mod.1.old.offset)
windows(11,8.5)
par(mfrow=c(2,2))
plot(mod.1.old.offset)
windows(11,8.5)
par(mfrow=c(2,2))
plot(mod.1.old.offset)
mod.1.old.offset <- lm(old~Year, data=db,weights = =old_offset) # Instead of using a ratio do the offset thing...
mod.1.old.offset <- lm(old~Year, data=db,weights =old_offset) # Instead of using a ratio do the offset thing...
par(mfrow=c(2,2))
plot(mod.1.old.offset)
windows(11,8.5)
boxplot(E1.old.stan~db$Management)
boxplot(E1.old.rat~db$Management)
windows(11,8.5)
par(mfrow=c(2,1))
boxplot(E1.old.stan~db$Management)
boxplot(E1.old.rat~db$Management)
windows(11,8.5)
par(mfrow=c(2,1))
boxplot(E1.old.stan~db$Management, main="Old Stan")
boxplot(E1.old.rat~db$Management, main="Old Ratio")
windows(11,8.5)
par(mfrow=c(2,1))
boxplot(E1.old.stan~db$Order, main="Old Stan") # nothing exciting here
boxplot(E1.old.rat~db$Order, main="Old Ratio") # NAFO and DFO's look low when we look this way...
mod.2.old.poisson <- glm(old~Year,data=db,offset=log(old_offset),family=poisson) # note their used to be a mod.1 when we had outliers in the data, they've been taken care of so mod.1 is gone..
warnings()
mod.2.old.poisson <- glm(old~Year,data=db,offset=log(old_offset),family=quasipoisson) # note their used to be a mod.1 when we had outliers in the data, they've been taken care of so mod.1 is gone..
summary(mod.2.old.poisson)
windows(11,8.5)
par(mfrow=c(2,2))
plot(mod.2.old.poisson)
E2.old.poisson <- resid(mod.2.old.poisson, type = "pearson")
Disp.stan <- sum(E2.old.poisson^2) / mod.2.old.poisson$df.res
Disp.stan
F2.old.poisson <- fitted(mod.2.old.poisson)
windows(11,8.5)
par(mfrow=c(1,1))
plot(x = F2.old.poisson,
y = E2.old.poisson,
xlab = "Fitted values",
ylab = "Pearson residuals")
abline(h=0,col="blue",lty=2)
F2.old.poisson <- fitted(mod.2.old.poisson)/log(db$old_offset)
windows(11,8.5)
par(mfrow=c(1,1))
plot(x = F2.old.poisson,
y = E2.old.poisson,
xlab = "Fitted values",
ylab = "Pearson residuals")
abline(h=0,col="blue",lty=2)
F2.old.poisson <- fitted(mod.2.old.poisson)/db$old_offset
windows(11,8.5)
par(mfrow=c(1,1))
plot(x = F2.old.poisson,
y = E2.old.poisson,
xlab = "Fitted values",
ylab = "Pearson residuals")
abline(h=0,col="blue",lty=2)
Disp.stan <- sum(E2.old.poisson/db$old_offset^2) / mod.2.old.poisson$df.res
Disp.stan
E2.old.poisson
E2.old.poisson <- resid(mod.2.old.poisson, type = "raw")
E2.old.poisson <- resid(mod.2.old.poisson, type = "deviance")
Disp.stan <- sum(E2.old.poisson^2) / mod.2.old.poisson$df.res
Disp.stan
E2.old.poisson
